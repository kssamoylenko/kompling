    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "colab_type": "code",
        "id": "syGkglti0YFf",
        "outputId": "e887df59-9ede-42b2-bee7-479f6dce29c2"
      },
      "cell_type": "code",
      "source": [
        "import artm\n",
        "%matplotlib inline\n",
        "import glob\n",
        "import os, re\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict, Counter\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "import gensim, nltk\n",
        "morph = MorphAnalyzer()\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/scipy/sparse/sparsetools.py:20: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
            "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
            "  _deprecated()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "colab_type": "code",
        "id": "DzdHfztLA1L8",
        "outputId": "30b64699-64a3-4856-8ecd-0efa0e5ee2a5"
      },
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "DGYYCeQh0YFl"
      },
      "cell_type": "markdown",
      "source": [
        "## Домашнее задание"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "-Gg8h2Ek0YFl"
      },
      "cell_type": "markdown",
      "source": [
        "Основаная задача - **построить хорошую тематическую модель с интерпретируемыми топиками**.\n",
        "\n",
        "1) сделайте нормализацию (если pymorphy2 работает долго используйте mystem или попробуйте установить быструю версию - `pip install pymorphy2[fast]`, можно использовать какой-то другой токенизатор) \n",
        "\n",
        "2) добавьте нграммы (в тетрадке есть закомменченая ячейка с Phrases); \n",
        "\n",
        "3) сохраните тексты .vw формате;\n",
        "\n",
        "4) сделайте хороший словарь (отфильтруйте слишком частотные и редкие слова, попробуйте удалить стоп-слова, сохраните словарь и посмотрите на него, вдруг что-то плохое сразу будет заметно); \n",
        "\n",
        "\n",
        "**Оцениваться будут главным образом пункты 6, 7 и 8. (3, 1, 4 баллов соответственно). Чтобы заработать остальные 2 балла, нужно хотя бы немного изменить мой код на промежуточных этапах (добавить что-то, указать другие параметры и т.д). **"
      ]
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "1hLw-SVu0YFm"
      },
      "cell_type": "code",
      "source": [
        "def remove_tags(text):\n",
        "    return re.sub(r'<[^>]+>', '', text)\n",
        "\n",
        "def clean(words):\n",
        "    clean = [morph.parse(word)[0].normal_form for word in words if word.isalnum()]\n",
        "    return clean"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "vlgqYxw90YFp"
      },
      "cell_type": "markdown",
      "source": [
        "## Возьмем теже данные"
      ]
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "colab_type": "code",
        "id": "mp_zp-zR5PJq",
        "outputId": "834f5790-6859-4da8-cc56-72d7ffaa23d1"
      },
      "cell_type": "code",
      "source": [
        "!wget https://github.com/mannefedov/compling_nlp_hse_course/raw/master/data/habr_texts.txt.zip"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-10-11 19:06:15--  https://github.com/mannefedov/compling_nlp_hse_course/raw/master/data/habr_texts.txt.zip\n",
            "Resolving github.com (github.com)... 192.30.253.112, 192.30.253.113\n",
            "Connecting to github.com (github.com)|192.30.253.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/mannefedov/compling_nlp_hse_course/master/data/habr_texts.txt.zip [following]\n",
            "--2018-10-11 19:06:15--  https://raw.githubusercontent.com/mannefedov/compling_nlp_hse_course/master/data/habr_texts.txt.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18645068 (18M) [application/zip]\n",
            "Saving to: ‘habr_texts.txt.zip’\n",
            "\n",
            "habr_texts.txt.zip  100%[===================>]  17.78M  27.1MB/s    in 0.7s    \n",
            "\n",
            "2018-10-11 19:06:16 (27.1 MB/s) - ‘habr_texts.txt.zip’ saved [18645068/18645068]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "colab_type": "code",
        "id": "COMPndhTAX1M",
        "outputId": "dea0e879-4d63-4eca-e42d-837d091d6d37"
      },
      "cell_type": "code",
      "source": [
        "!unzip habr_texts.txt.zip"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  habr_texts.txt.zip\n",
            "  inflating: habr_texts.txt          \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oXdZcOTVibKJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "696df8e2-ef86-48e5-a0b7-3a62119a3e98"
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "NDHkAaPb0YFp"
      },
      "cell_type": "code",
      "source": [
        "habr_texts = [clean(word_tokenize(remove_tags(text.lower()))) for text in open('habr_texts.txt')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "o_yHUX490YFr"
      },
      "cell_type": "code",
      "source": [
        "# вернемся сюда через какое-то время\n",
        "ph = gensim.models.Phrases(habr_texts, scoring='npmi', threshold=0.3, \n",
        "                           common_terms=set(stopwords.words('russian'))) # можно указать слова, которые \n",
        "                                                                          # не будут учитываться\n",
        "p = gensim.models.phrases.Phraser(ph)\n",
        "ngrammed_habr_texts = p[habr_texts]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "5q3JXJV40YFt"
      },
      "cell_type": "code",
      "source": [
        "#p[habr_texts[1]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "vOiEF_5H0YFv"
      },
      "cell_type": "markdown",
      "source": [
        "Для BigARTM требуется специальный формат данных. Их несколько, но мы возьмем vowpal wabbit.  \n",
        "На каждой строчке файла находится одельный текст, записывается такст вот таким образом:  \n",
        "```doc_name |@class_id word_1:1 word_2:3```  \n",
        "\n",
        "|@class_id - задает модальность, но когда она одна её можно не указывать.\n",
        "\n",
        "word_2:3 - слово и его частота (обратите внимание, что : - специальный символ и в словах его быть не может"
      ]
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "SZD1bmhR0YFw"
      },
      "cell_type": "code",
      "source": [
        "f = open('habr_texts.vw', 'w')\n",
        "\n",
        "for i, text in enumerate(habr_texts):\n",
        "    c = Counter(text)\n",
        "    doc = 'doc_'+ str(i) + ' '\n",
        "    vw_text = ' '.join([x+':'+str(c[x]) for x in c])\n",
        "    \n",
        "    f.write(doc + vw_text  + '\\n')\n",
        "f.close()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "VO4xO6zT0YFy"
      },
      "cell_type": "markdown",
      "source": [
        "Для оценки будем использовать такую функцию (из туториалов от создателей библиотеки)"
      ]
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "xchX4sBs0YFz"
      },
      "cell_type": "code",
      "source": [
        "def print_measures(model_artm):\n",
        "    print('Sparsity Phi: {0:.3f} ARTM)'.format(\n",
        "        model_artm.score_tracker['SparsityPhiScore'].last_value)\n",
        ")\n",
        "    print('Sparsity Theta: {0:.3f} (ARTM)'.format(\n",
        "        model_artm.score_tracker['SparsityThetaScore'].last_value))\n",
        "\n",
        "    print('Kernel contrast: {0:.3f} (ARTM)'.format(\n",
        "        model_artm.score_tracker['TopicKernelScore'].last_average_contrast))\n",
        "\n",
        "    print('Kernel purity: {0:.3f} (ARTM)'.format(\n",
        "        model_artm.score_tracker['TopicKernelScore'].last_average_purity))\n",
        "\n",
        "    print('Perplexity: {0:.3f} (ARTM)'.format(\n",
        "        model_artm.score_tracker['PerplexityScore'].last_value)\n",
        ")\n",
        "    plt.plot(range(model_artm.num_phi_updates), model_artm.score_tracker['PerplexityScore'].value, 'r--', linewidth=2)\n",
        "    plt.xlabel('Iterations count')\n",
        "    plt.ylabel(' ARTM perp. (red)')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "GHFVe6gK0YF2"
      },
      "cell_type": "markdown",
      "source": [
        "BigARTM работает не с целым файлом, а с кусочками. Поэтому разбиваем наш .vw файл специальным классом в artm."
      ]
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "NhIADC8O0YF2"
      },
      "cell_type": "code",
      "source": [
        "batch_vectorizer = artm.BatchVectorizer(data_path='habr_texts.vw',  # название файла\n",
        "                                        data_format='vowpal_wabbit', # формат файла, у нас vw\n",
        "                                        target_folder='batches', # название папки в которую положаться батчи\n",
        "                                       batch_size=1000) # размер батча, подбирайте под свою память"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ZjXpddzi0YF6"
      },
      "cell_type": "markdown",
      "source": [
        "Уже созданные батчи можно заново загружать"
      ]
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "AG7xR0gu0YF6"
      },
      "cell_type": "code",
      "source": [
        "batch_vectorizer = artm.BatchVectorizer(data_path='batches', # название папки с батчами\n",
        "                                        data_format='batches') # указываем формат - батчи"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Qe0-ERcn0YF8"
      },
      "cell_type": "code",
      "source": [
        "# инициализируем словарь, чтобы сделать модель\n",
        "dictionary = artm.Dictionary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "sNAKhYQZ0YF-"
      },
      "cell_type": "markdown",
      "source": [
        "Собираем словарь по батчам"
      ]
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "S6nXvdOq0YGA",
        "outputId": "ff80e108-7030-4f0d-89f9-ced37e17af83"
      },
      "cell_type": "code",
      "source": [
        "dictionary.gather(data_path='batches')\n",
        "dictionary.filter(class_id='@default_class',\n",
        "                  min_df=10, max_df=2000)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "artm.Dictionary(name=83e1d7db-a099-4908-bbf1-cad6d25c21a3, num_entries=15390)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "HEuyJjlB0YGB"
      },
      "cell_type": "markdown",
      "source": [
        "Его можно сохранить, чтобы не создавать снова или чтобы посмотреть и подредактировать."
      ]
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "I273a14r0YGC"
      },
      "cell_type": "code",
      "source": [
        "dictionary.save_text('dict.txt')\n",
        "# dictionary = artm.Dictionary()\n",
        "# dictionary.load_text('dict.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "bdMCSZiB0YGE"
      },
      "cell_type": "markdown",
      "source": [
        "Создаем модель и сразу включаем два регуляризатора (Декореляции и Сглаживания)"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "LXN_YR1m0YGF"
      },
      "cell_type": "markdown",
      "source": [
        "`artm.DecorrelatorPhiRegularizer` - регуляризатор декорреляции тем, делает темы менее похожими друг на друга (рекомендуется включать его сразу на всех темах с положительным значением tau и не менять его в процессе обучения)  \n",
        "\n",
        "`artm.SmoothSparsePhiRegularizer` - регуляризатор сглаживания/разреженивания Phi (тем) - сглаживает или расреживает распределение слов в темах (отрицательный tau - разреживает, положительный - сглаживает), рекомендуется сразу включать сглаживание на всех темах и не менять его в процессе обучения;\n",
        "\n",
        "Количество тем нужно подбирать, но 200 часто работает хорошо. Снижение количества тем и уменьшения словаря ведут к уменьшению времени обучения модели (а увеличение, наоборот). "
      ]
    },
    {
      "metadata": {
        "id": "FUz3di2urzot",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "5) постройте несколько ARTM моделей (переберите количество тем, поменяйте значения tau у регуляризаторов), если получаются плохие темы, поработайте дополнительно над предобработкой и словарем; \n",
        "\n",
        "6) для самой хорошей модели в отдельной ячейке напечатайте 3 хороших (на ваш вкус) темы\n",
        "\n",
        "7) в другой ячейки нарисуйте график обучения этой модели \n",
        "\n",
        "8) в третьей ячейки опишите какие параметры (количество тем, регуляризаторы, их tau) вы использовали и как обучали (например, после скольки проходов добавили регуляризатор разрежнивания тем (Phi), добавляли ли разреженность документам (Theta) и когда, как повышали значения, сколько итерации модель продожала улучшаться (снижалась перплексия, росли другие метрики);\n",
        "\n",
        "Сохраните тетрадку с экспериментами и положите её на гитхаб, ссылку на неё укажите в форме.\n"
      ]
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "7gTUMUh90YGG"
      },
      "cell_type": "code",
      "source": [
        "model_artm = artm.ARTM(topic_names=['topic_{}'.format(i) for i in range(200)],\n",
        "                       \n",
        "                       regularizers=[\n",
        "                           artm.DecorrelatorPhiRegularizer(\n",
        "                                            name='Decorr', tau=0.25, \n",
        "                                            class_ids=['@default_class'],\n",
        "                                            topic_names=['topic_{}'.format(i) for i in range(0, 200)]),\n",
        "                           \n",
        "                           artm.SmoothSparsePhiRegularizer(\n",
        "                                            name='SmoothPhi_1', \n",
        "                                            class_ids=['@default_class'],\n",
        "                                            tau=0.15, \n",
        "                                            topic_names=['topic_{}'.format(i) for i in range(0, 200)])\n",
        "                                    ]\n",
        "                        )\n",
        "\n",
        "# не забывайте менять количество топиков в регуляризаторах, они применяются только на тех темах, что заданы"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2MtLvu4wr_KO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_artm1 = artm.ARTM(topic_names=['topic_{}'.format(i) for i in range(20)],\n",
        "                       \n",
        "                       regularizers=[\n",
        "                           artm.DecorrelatorPhiRegularizer(\n",
        "                                            name='Decorr', tau=0.45, \n",
        "                                            class_ids=['@default_class'],\n",
        "                                            topic_names=['topic_{}'.format(i) for i in range(0, 20)]),\n",
        "                           \n",
        "                           artm.SmoothSparsePhiRegularizer(\n",
        "                                            name='SmoothPhi_1', \n",
        "                                            class_ids=['@default_class'],\n",
        "                                            tau=0.15, \n",
        "                                            topic_names=['topic_{}'.format(i) for i in range(0, 20)])\n",
        "                                    ]\n",
        "                        )\n",
        "\n",
        "# не забывайте менять количество топиков в регуляризаторах, они применяются только на тех темах, что заданы"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hb-69uROtZVI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_artm2 = artm.ARTM(topic_names=['topic_{}'.format(i) for i in range(10)],\n",
        "                       \n",
        "                       regularizers=[\n",
        "                           artm.DecorrelatorPhiRegularizer(\n",
        "                                            name='Decorr', tau=0.55, \n",
        "                                            class_ids=['@default_class'],\n",
        "                                            topic_names=['topic_{}'.format(i) for i in range(0, 10)]),\n",
        "                           \n",
        "                           artm.SmoothSparsePhiRegularizer(\n",
        "                                            name='SmoothPhi_1', \n",
        "                                            class_ids=['@default_class'],\n",
        "                                            tau=0.15, \n",
        "                                            topic_names=['topic_{}'.format(i) for i in range(0, 10)])\n",
        "                                    ]\n",
        "                        )\n",
        "\n",
        "# не забывайте менять количество топиков в регуляризаторах, они применяются только на тех темах, что заданы"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ZXwur8c80YGI"
      },
      "cell_type": "code",
      "source": [
        "# инициализурем модель словарем\n",
        "model_artm2.initialize(dictionary=dictionary, )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "M7ofKFaN0YGK"
      },
      "cell_type": "code",
      "source": [
        "# добавляем метрики\n",
        "model_artm2.scores.add(artm.PerplexityScore(name='PerplexityScore',\n",
        "                                                    dictionary=dictionary))\n",
        "model_artm2.scores.add(artm.SparsityPhiScore(name='SparsityPhiScore')) # разреженность слов в темах\n",
        "model_artm2.scores.add(artm.SparsityThetaScore(name='SparsityThetaScore')) # разреженность тем в доках\n",
        "model_artm2.scores.add(artm.TopicKernelScore(name='TopicKernelScore', probability_mass_threshold=0.1)) # когерентность по семантичесим ядрам\n",
        "model_artm2.scores.add(artm.TopTokensScore(class_id='@default_class', name='TopTokensScore_1', num_tokens=10)) # топ-n-слов для каждой темы "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zu66SySWryBT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "A7ih3cp10YGM"
      },
      "cell_type": "markdown",
      "source": [
        "### Тренируем модель"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "vkujg5tp0YGN"
      },
      "cell_type": "markdown",
      "source": [
        "Пройдемся несколько раз по коллекции, чтобы модель немного сошлась (если доков сильно больше то может быть достаточно и 1 прохода). Для сильно больших коллекций есть fit_online, который обновляется в процессе прохода по коллекции, про него можно почитать в документации."
      ]
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "d3UPM4bd0YGO"
      },
      "cell_type": "code",
      "source": [
        "model_artm2.num_document_passes = 2\n",
        "model_artm2.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "sJNAHoO30YGR"
      },
      "cell_type": "code",
      "source": [
        "# посмотрим, что стало с моделью\n",
        "# если график сильно падал на последних итерациях, то можно прогнать обучение ещё несколько раз \n",
        "# (не добавляя другие регуляризаторы)\n",
        "#print_measures(model_artm2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "zx8f5J140YGU"
      },
      "cell_type": "code",
      "source": [
        "model_artm2.regularizers.add(artm.SmoothSparsePhiRegularizer(name='SparsePhi', tau=-0.15, \n",
        "                                                            topic_names=['topic_{}'.format(i) for i in range(1, 10)],\n",
        "                                                            ))\n",
        "model_artm2.regularizers.add(artm.SmoothSparseThetaRegularizer(name='SparseTheta', tau=-0.15, \n",
        "                                                              topic_names=['topic_{}'.format(i) for i in range(1, 10)]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "d-XyXPrF0YGX"
      },
      "cell_type": "code",
      "source": [
        "model_artm2.fit_offline(batch_vectorizer=batch_vectorizer,num_collection_passes=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "CWrgduzK0YGY"
      },
      "cell_type": "code",
      "source": [
        "# будем постепенно увеличивать значения этих регуляризаторов\n",
        "phi_tau = model_artm2.regularizers['SparsePhi'].tau\n",
        "theta_tau = model_artm2.regularizers['SparseTheta'].tau\n",
        "\n",
        "for i in range(10):\n",
        "    model_artm2.regularizers['SparsePhi'].tau = (phi_tau + (phi_tau*0.5))\n",
        "    model_artm2.regularizers['SparseTheta'].tau = (theta_tau + (theta_tau*0.1))\n",
        "    \n",
        "    model_artm2.fit_offline(batch_vectorizer=batch_vectorizer,num_collection_passes=1)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "colab_type": "code",
        "id": "Nz2ZycN80YGb",
        "outputId": "01134dbe-5224-41aa-c9cc-ce19c65a3bf8"
      },
      "cell_type": "code",
      "source": [
        "# посмотрим на качество\n",
        "print_measures(model_artm2)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sparsity Phi: 0.277 ARTM)\n",
            "Sparsity Theta: 0.001 (ARTM)\n",
            "Kernel contrast: 0.301 (ARTM)\n",
            "Kernel purity: 0.800 (ARTM)\n",
            "Perplexity: 3261.249 (ARTM)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEGCAYAAABy53LJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhB3z1OHZAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f3bb2c73550>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "r0pGwdLb0YGg"
      },
      "cell_type": "markdown",
      "source": [
        "Перплексия должна снижаться. Если график выровнился и больше не меняется - модель сошлась. Обычно перплексия хорошей модели около 200-1000. На таком небольшом количестве данных возможно такого значения достичь не получится."
      ]
    },
    {
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "tDeYG2kt0YGg"
      },
      "cell_type": "code",
      "source": [
        "# посмотрим на темы\n",
        "#for topic_name in model_artm2.topic_names[:10]:\n",
        "#    print(topic_name + ': ')\n",
        "#    try:\n",
        "#        for x in model_artm2.score_tracker['TopTokensScore_1'].last_tokens[topic_name]:\n",
        "#            print(x)\n",
        "#        print('---------')\n",
        "    \n",
        "#    except KeyError: # можно перекрутить параметры и некоторые темы окажутся пустыми\n",
        "#        continue"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "colab_type": "code",
        "id": "NAUy5VNu0YGi",
        "outputId": "b5b75ac2-f71f-4cd0-e783-d4255206ec4c"
      },
      "cell_type": "code",
      "source": [
        "for topic_name in model_artm2.topic_names[3:6]:\n",
        "    print(topic_name + ': ')\n",
        "    try:\n",
        "        for x in model_artm2.score_tracker['TopTokensScore_1'].last_tokens[topic_name]:\n",
        "            print(x)\n",
        "        print('---------')\n",
        "    \n",
        "    except KeyError: # можно перекрутить параметры и некоторые темы окажутся пустыми\n",
        "        continue"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "topic_3: \n",
            "решение\n",
            "компания\n",
            "проект\n",
            "разработка\n",
            "инструмент\n",
            "результат\n",
            "информация\n",
            "технология\n",
            "задача\n",
            "процесс\n",
            "---------\n",
            "topic_4: \n",
            "задача\n",
            "количество\n",
            "говорить\n",
            "результат\n",
            "сам\n",
            "проект\n",
            "общий\n",
            "интересный\n",
            "потому\n",
            "нужный\n",
            "---------\n",
            "topic_5: \n",
            "устройство\n",
            "технология\n",
            "сигнал\n",
            "область\n",
            "скорость\n",
            "компания\n",
            "камера\n",
            "позволять\n",
            "место\n",
            "материал\n",
            "---------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OtmolxVHrjSO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-viJi0IhvN-o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Последняя из опробованных  моделей оказалась самой удачной. Я постепенно снижала количество тем и одновременно повышала тау, это позволило постепенно получить более осмысленные наборы слов для тем. Для всех моделей я добавляла регуляризаторы, в результате чего перплексия становилась на порядок ниже."
      ]
    },
    {
      "metadata": {
        "id": "Z-yLPAFLv02B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
